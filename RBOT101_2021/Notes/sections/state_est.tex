\chapter{State Estimation}
\label{chap:state_ext}

The next few topics in this course shall involve the quantification of uncertainty in order to enable a robot navigate, move, or understand its environment via visual or audio sensors. In order to do justice to this topic, we shall soon find out that the concept of putting a value or percentage on how sure we are about a robot's environment shall be very helpful in effective control of our robots. Thus the concept of probability shall greatly aid us in quantifying uncertainty. Even so, we introduce the concept of states, grounded in a mathematical theory that allows the engineer to implement a state through discrete-time systems (since we assume that most implementations shall be done on digital computers). By the \textit{state} of a system, we shall loosely mean ``those variables that provide a complete representation of the internal condition ot status of the system at a given time instant." In this sentiment, the states of a motor system may mean currents that flow through the inductive coils, the position and speed of motor shaft, or the voltage across the coils of a solenoid valve. The states of a military power may include the number of its aircraft carriers, the size and horsepower of its nuclear submarines, the number of enlisted servicemen in its forces e.t.c. For a biological system, the states might include blood sugar levels, heart and respiration rates, or body temperature.

Robot systems may include mobile platforms for extraterrestrial navigation, robotics arms in assembly lines, autonomous cars, or actuated surgical devices that assist surgeons. Our goal is to treat uncertainty. Uncertainty occurs if the robot lacks important information that hinders it from carrying out assigned tasks. We may classify this uncertainty into five different factors, viz.,
%
\begin{enumerate}
	\item \textbf{Environments.} The physical worlds is inherently unpredictable. While the degree of uncertainty in well-structured environments such assembly lines is small, environments such as highways and private homes are highly dynamic and unpredictable.
	%
	\item \textbf{Sensors.} Most sensors have limitations in their perceptual ability arising from noise and the range and the resolution of the sensors. For example, environmental disturbances, weather, lighting conditions limit the information that can be extracted from sensors. Secondly, as to range and resolution, cameras cannot see through walls despite the perceptual range that the spatial resolution of the camera is limited.
	%
	\item \textbf{Models.} In general, models are at best an approximation or a mathematical representation or abstraction of the physical world. As such, model errors are a source of uncertainty that need to be incorporated in modeling robotics problems.
	%
	\item \textbf{Computation.} Being real-time systems, robots require a lot of computation in order to be able to achieve timely-response through sacrificing accuracy.
\end{enumerate}

We will estimate states as they shall represent latent or underlying variables that influence the physical or chemical or financial properties of the system. And in motivating the study of a system's state, we can resolve to many weapons in our estimation arsenal which may include linear state filtering (the simple Kalman filter), nonlinear state filters (the extended Kalman filter, unscented Kalman filter e.t.c.), Bayesian estimation, and \textit{frequentist/classical} estimation approaches. In general, state estimation is an important topic to the engineer because:
%
\begin{itemize}
	\item We may need to implement a feedback controller in order to regulate a system's behavior. If the application was for a surgeon to regulate blood pH levels, we may need to estimate the system's state. Or if the challenge is to adequately position a patient's head to a position in 3D space during cancer stereotactic radiosurgery, we may need to estimate the position and orientation of the patient's head and neck in the inertial frame.
	%
	\item If the states in question are curious enough, we may want to measure these states to understand the faults tolerance of the system in order to perform a good fault identification and prognosis. For example, we might want to estimate the internal states of an aircraft system in flight such that if an aircraft engine fails during flight, we can safely monitor system states in real-time in order to determine how long we can continue flying the aircraft or if we should quickly find a near-by airport where we could land the aircraft for maintenance.
\end{itemize} 
%
In our treatment, therefore, we shall give a brief introduction to linear systems theory, touch upon standard linear filters and then proceed to treat probability theory before we treat frequentist and Bayes inference for classification, and decision-making.

\section{Linear Systems}

State-space systems are very important in engineering systems because they allow us to gain insight into the characteristics of the system, be able to predict future behaviors of the system, as well as identify the controllable and observable states of the system. The mathematical model of the process allows us to infer the information about the process. State-space models can be classified into linear and nonlinear systems. While most real-world systems are nonlinear, the tools that exist for analyzing and synthesizing nonlinear systems  are well-developed and sophisticated that most nonlinear systems can be approximated by linear systems in order to exercise good control and estimation for real-world applications.

A continuous-time, deterministic linear system can be described by the equations 
%
\begin{align}
	\dot{x} &= Ax + Bu \nonumber \\
	y &= Cx
\end{align}
%
where $x$ is the \textit{state vector} in $\mathbb{R}^n \times 1$, $u$ is the \textit{control vector} in $\mathbb{R}^p \times 1$, and $y$ is an  $\mathbb{R}^n \times 1$ vector. Matrices $A$, $B$, and $C$ are respectively $n\times n$, $n \times p$ and $n \times 1$ in dimension. The matrix $A$ is often called the system matrix, $B$ the input or control matrix, while $C$ is often called the output matrix. $A, B$, and $C$ can be time-varying matrices, in which case the system is linear. Otherwise, the solution to the linear system of equations above is 
%
\begin{align}
	x(t) &= e^{A(t-t_0)} x(t_0) + \int_{t_0}^{t} e^{A(t-\tau)} B u(\tau) d\tau  \\
	y(t) &= C x(t)
	\label{eq:matrix_exp}
\end{align}
%
where $t_0$ is the initial time of the system. If the input control law is zero, then we have 
%
\begin{align}
	x(t) &= e^{A(t-t_0)} x(t_0) 
\end{align}
%
and because of this, $e^{AT}$ is called the state-transition matrix \ie it describes how the state moves between transitions at different times regardless of external inputs. At $t = t_0$, we have that 
%
\begin{align}
	e^{A \, 0} = I,
\end{align}
%
which is similar to the scalar exponential of a zero. What happens if $x$ is an $n$-element vector? The solution in \eqref{eq:matrix_exp} still remains valid but we must note that the exponential of the matrix becomes interpreted as 
%
\begin{align}
	e^{At} &= \sum_{j=0}^{\infty} \dfrac{(At)^j}{j!} \nonumber \\
	&= \mathcal{L}^{-1} \left[sI - A\right]^{-1} = Q e^{\hat{A}t} Q^{-1}
	\label{eq:matrix_exp_jordan}
\end{align}
%
where the symbol $\mathcal{L}^{-1}$ is the symbol for the inverse Laplace transform and $``s"$ is the Laplace operator. We see that $A$ must be square in order for $e^{At}$ to exist. $Q$ contains the eigenvectors of $A$ and $\hat{A}$ are the Jordan form of $A$.
%
\begin{quiz}
	Write a note about the Jordan form. Also, explain how it can be determined from \eqref{eq:matrix_exp_jordan}.
	% ANS
	% \eqref{eq:matrix_exp_jordan} can be used to define the Jordan form of the matrix. 
\end{quiz}
%
\begin{quiz}
	Does the matrix $A$ commute with its exponential i.e. does $A \, e^{At} = e^{At} \, A$? 
\end{quiz}

The matrix $\hat{A}$ is often diagonal, so that case $e^{\hat{A}t}$ can be computed as
%
\begin{align}
	\hat{A} = \begin{bmatrix}
	\hat{A}_{11} & 0 & \ldots & 0 \\
		0 & \hat{A}_{22} & \ldots 0 \\
		\vdots & \ddots & \ddots & \vdots \\
		0 & \ldots & \ldots & \hat{A}_{nn} 
	\end{bmatrix} \quad 
	%	
	e^{\hat{A}t} = \begin{bmatrix}
	e^{\hat{A}_{11}} & 0 & \ldots & 0 \\
	0 & e^{\hat{A}_{22}} & \ldots 0 \\
	\vdots & \ddots & \ddots & \vdots \\
	0 & \ldots & \ldots & e^{\hat{A}_{nn}}
	\end{bmatrix}
\end{align}

From \eqref{eq:matrix_exp_jordan}, we can write 
%
\begin{align}
	\left[e^{At}\right]^{-1} = e^{-At} = Q e ^{-\hat{A}t} Q^{-1}
\end{align}
%
Since $A$ and $-A$ have eigenvalues that are negative of each other, $e^{At}$ is always invertible.

\begin{example}
	Suppose we are controlling angular heading of a mobile robot (for example, using voltage applied to its wheels' rotor windings in order to generate command velocity along the $x$, $y$, and $z$ heading, i.e. $\theta$, $\omega$ and $\alpha$ respectively). The derivative of the angular velocity vector can be written as 
	%
	\begin{align}
	\dot{\theta} &= \omega + \alpha + 3.5 \omega_1 + 6 \theta_2 \nonumber \\
	\dot{\omega} &= u + 0.1 \theta  + 2.5 \alpha + \omega_1 + \omega_2^2\nonumber \\
		\dot{\alpha} &= \theta_1 + 2 u %\nonumber \\
	\end{align}
	%
	The scalars $\omega_1$, $\omega_2$, $\theta_1$ and $\theta_2$ are acceleration noise terms such as gear backlash, friction, and modeling errors. If our measurement consists of the $\theta$ and $\omega$ states, it follows that we can write the state space equation as 
	%
	\begin{align}
		\begin{bmatrix}
		 \dot{\theta} \\ \dot{\omega} \\ \dot{\alpha}
		\end{bmatrix}
		& =
		\begin{bmatrix}
		0 & 1 & 1 \\
		1 & 0 & 2.5 \\
		0 & 0 & 0
		\end{bmatrix}
		+
		\begin{bmatrix}
		0 \\ 1 \\ 2
		\end{bmatrix} u
		+
		\begin{bmatrix}
		 3.5 \omega_1 + 6 \theta_2 \\
		 \omega_1 + \omega_2^2 \\
		 \theta_1
		\end{bmatrix} \nonumber \\
		%
		y &= \begin{bmatrix}
		1 & 1 & 0
		\end{bmatrix} +
		\begin{bmatrix}
		\theta \\ \omega \\ \alpha
		\end{bmatrix} + \begin{bmatrix}
		{v_x} \\ {v_y} \\ {v_z}
		\end{bmatrix}
	\end{align}
	where $v = [v_x, v_y, v_z]^T$ is the linear velocity vector for  the robot.
\end{example}

\begin{example}
	Suppose that 
	\begin{align}
		A = \begin{bmatrix}
		0 & 1 \\ 0 & 0
		\end{bmatrix}
	\end{align}
	%
	It follows that
	%
	\begin{align}
		e^{At} &= \sum_{j=0}^{\infty} \dfrac{(At)^j}{j!} \nonumber \\
		       &= (At)^0 + (At)^1 + \frac{(At)^2}{2!} +  \frac{(At)^3}{3!} + \ldots \nonumber \\
		       &= I + At
	\end{align}	
	where the last term follows from the fact that $A^k = 0$ for $k>1$ so that 
	%
	\begin{align}
		e^{At} = \begin{bmatrix}
		1 & 0 \\ 0 & 1
		\end{bmatrix}
		+ 
		\begin{bmatrix}
		0 & t \\ 0 & 0
		\end{bmatrix}
		= 
		\begin{bmatrix}
		1 & t \\ 0 & 1
		\end{bmatrix}
	\end{align}
	%
	Using the expression for the inverse Laplace transform earlier, we have 
	%
	\begin{align}
		e^{At} &= \mathcal{L}^{-1}\left[\left(sI-A\right)^{-1}\right] \nonumber \\
		&= \mathcal{L}^{-1}\left(
		\begin{bmatrix}
		s & -1 \\ 0 & s
		\end{bmatrix}^{-1}\right) \nonumber \\
		&= \mathcal{L}^{-1} 
		\begin{bmatrix}
		1/s & 1/s^2 \\ 0 & 1/s
		\end{bmatrix} \nonumber \\
		&= \begin{bmatrix}
		1 & t \\ 0 & 1
		\end{bmatrix}
		\label{eq:example_matrix_eq}
	\end{align}
\end{example}

\begin{homework}
	Find the eigendata of the matrix A in \eqref{eq:example_matrix_eq}. Then determine the following terms using the eigenvector and eigenvalue that you may find
	$\hat{A}, Q$ and $e^{At}$.
\end{homework}
