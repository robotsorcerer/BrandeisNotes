\chapter{State Estimation}
\label{chap:state_ext}

The next few topics in this course shall involve the quantification of uncertainty in order to enable a robot navigate, move, or understand its environment via visual or audio sensors. In order to do justice to this topic, we shall soon find out that the concept of putting a value or percentage on how sure we are about a robot's environment shall be very helpful in effective control of our robots. Thus the concept of probability shall greatly aid us in quantifying uncertainty. Even so, we introduce the concept of states, grounded in a mathematical theory that allows the engineer to implement a state through discrete-time systems (since we assume that most implementations shall be done on digital computers). By the \textit{state} of a system, we shall loosely mean ``those variables that provide a complete representation of the internal condition ot status of the system at a given time instant." In this sentiment, the states of a motor system may mean currents that flow through the inductive coils, the position and speed of motor shaft, or the voltage across the coils of a solenoid valve. The states of a military power may include the number of its aircraft carriers, the size and horsepower of its nuclear submarines, the number of enlisted servicemen in its forces e.t.c. For a biological system, the states might include blood sugar levels, heart and respiration rates, or body temperature.

Robot systems may include mobile platforms for extraterrestrial navigation, robotics arms in assembly lines, autonomous cars, or actuated surgical devices that assist surgeons. Our goal is to treat uncertainty. Uncertainty occurs if the robot lacks important information that hinders it from carrying out assigned tasks. We may classify this uncertainty into five different factors, viz.,
%
\begin{enumerate}
	\item \textbf{Environments.} The physical worlds is inherently unpredictable. While the degree of uncertainty in well-structured environments such assembly lines is small, environments such as highways and private homes are highly dynamic and unpredictable.
	%
	\item \textbf{Sensors.} Most sensors have limitations in their perceptual ability arising from noise and the range and the resolution of the sensors. For example, environmental disturbances, weather, lighting conditions limit the information that can be extracted from sensors. Secondly, as to range and resolution, cameras cannot see through walls despite the perceptual range that the spatial resolution of the camera is limited.
	%
	\item \textbf{Models.} In general, models are at best an approximation or a mathematical representation or abstraction of the physical world. As such, model errors are a source of uncertainty that need to be incorporated in modeling robotics problems.
	%
	\item \textbf{Computation.} Being real-time systems, robots require a lot of computation in order to be able to achieve timely-response through sacrificing accuracy.
\end{enumerate}

We will estimate states as they shall represent latent or underlying variables that influence the physical or chemical or financial properties of the system. And in motivating the study of a system's state, we can resolve to many weapons in our estimation arsenal which may include linear state filtering (the simple Kalman filter), nonlinear state filters (the extended Kalman filter, unscented Kalman filter e.t.c.), Bayesian estimation, and \textit{frequentist/classical} estimation approaches. In general, state estimation is an important topic to the engineer because:
%
\begin{itemize}
	\item We may need to implement a feedback controller in order to regulate a system's behavior. If the application was for a surgeon to regulate blood pH levels, we may need to estimate the system's state. Or if the challenge is to adequately position a patient's head to a position in 3D space during cancer stereotactic radiosurgery, we may need to estimate the position and orientation of the patient's head and neck in the inertial frame.
	%
	\item If the states in question are curious enough, we may want to measure these states to understand the faults tolerance of the system in order to perform a good fault identification and prognosis. For example, we might want to estimate the internal states of an aircraft system in flight such that if an aircraft engine fails during flight, we can safely monitor system states in real-time in order to determine how long we can continue flying the aircraft or if we should quickly find a near-by airport where we could land the aircraft for maintenance.
\end{itemize} 
%
In our treatment, therefore, we shall give a brief introduction to linear systems theory, touch upon standard linear filters and then proceed to treat probability theory before we treat frequentist and Bayes inference for classification, and decision-making.

\section{Linear Systems}

State-space systems are very important in engineering systems because they allow us to gain insight into the characteristics of the system, be able to predict future behaviors of the system, as well as identify the controllable and observable states of the system. The mathematical model of the process allows us to infer the information about the process. State-space models can be classified into linear and nonlinear systems. While most real-world systems are nonlinear, the tools that exist for analyzing and synthesizing nonlinear systems  are well-developed and sophisticated that most nonlinear systems can be approximated by linear systems in order to exercise good control and estimation for real-world applications.

A continuous-time, deterministic linear system can be described by the equations 
%
\begin{align}
	\dot{x} &= Ax + Bu \nonumber \\
	y &= Cx
\end{align}
%
where $x$ is the \textit{state vector} in $\mathbb{R}^n \times 1$, $u$ is the \textit{control vector} in $\mathbb{R}^p \times 1$, and $y$ is an  $\mathbb{R}^n \times 1$ vector. Matrices $A$, $B$, and $C$ are respectively $n\times n$, $n \times p$ and $n \times 1$ in dimension. The matrix $A$ is often called the system matrix, $B$ the input or control matrix, while $C$ is often called the output matrix. $A, B$, and $C$ can be time-varying matrices, in which case the system is linear. Otherwise, the solution to the linear system of equations above is 
%
\begin{align}
	x(t) &= e^{A(t-t_0)} x(t_0) + \int_{t_0}^{t} e^{A(t-\tau)} B u(\tau) d\tau  \\
	y(t) &= C x(t)
	\label{eq:matrix_exp}
\end{align}
%
where $t_0$ is the initial time of the system. If the input control law is zero, then we have 
%
\begin{align}
	x(t) &= e^{A(t-t_0)} x(t_0) 
\end{align}
%
and because of this, $e^{AT}$ is called the state-transition matrix \ie it describes how the state moves between transitions at different times regardless of external inputs. At $t = t_0$, we have that 
%
\begin{align}
	e^{A \, 0} = I,
\end{align}
%
which is similar to the scalar exponential of a zero. What happens if $x$ is an $n$-element vector? The solution in \eqref{eq:matrix_exp} still remains valid but we must note that the exponential of the matrix becomes interpreted as 
%
\begin{align}
	e^{At} &= \sum_{j=0}^{\infty} \dfrac{(At)^j}{j!} \nonumber \\
	&= \mathcal{L}^{-1} \left[sI - A\right]^{-1} = Q e^{\hat{A}t} Q^{-1}
	\label{eq:matrix_exp_jordan}
\end{align}
%
where the symbol $\mathcal{L}^{-1}$ is the symbol for the inverse Laplace transform and $``s"$ is the Laplace operator. We see that $A$ must be square in order for $e^{At}$ to exist. $Q$ contains the eigenvectors of $A$ and $\hat{A}$ are the Jordan form of $A$.
%
\begin{quiz}
	Write a note about the Jordan form. Also, explain how it can be determined from \eqref{eq:matrix_exp_jordan}.
	% ANS
	% \eqref{eq:matrix_exp_jordan} can be used to define the Jordan form of the matrix. 
\end{quiz}
%
\begin{quiz}
	Does the matrix $A$ commute with its exponential i.e. does $A \, e^{At} = e^{At} \, A$? 
\end{quiz}

The matrix $\hat{A}$ is often diagonal, so that case $e^{\hat{A}t}$ can be computed as
%
\begin{align}
	\hat{A} = \begin{bmatrix}
	\hat{A}_{11} & 0 & \ldots & 0 \\
		0 & \hat{A}_{22} & \ldots 0 \\
		\vdots & \ddots & \ddots & \vdots \\
		0 & \ldots & \ldots & \hat{A}_{nn} 
	\end{bmatrix} \quad 
	%	
	e^{\hat{A}t} = \begin{bmatrix}
	e^{\hat{A}_{11}} & 0 & \ldots & 0 \\
	0 & e^{\hat{A}_{22}} & \ldots 0 \\
	\vdots & \ddots & \ddots & \vdots \\
	0 & \ldots & \ldots & e^{\hat{A}_{nn}}
	\end{bmatrix}
\end{align}

From \eqref{eq:matrix_exp_jordan}, we can write 
%
\begin{align}
	\left[e^{At}\right]^{-1} = e^{-At} = Q e ^{-\hat{A}t} Q^{-1}
\end{align}
%
Since $A$ and $-A$ have eigenvalues that are negative of each other, $e^{At}$ is always invertible.

\begin{example}
	Suppose we are controlling angular heading of a mobile robot (for example, using voltage applied to its wheels' rotor windings in order to generate command velocity along the $x$, $y$, and $z$ heading, i.e. $\theta$, $\omega$ and $\alpha$ respectively). The derivative of the angular velocity vector can be written as 
	%
	\begin{align}
	\dot{\theta} &= \omega + \alpha + 3.5 \omega_1 + 6 \theta_2 \nonumber \\
	\dot{\omega} &= u + 0.1 \theta  + 2.5 \alpha + \omega_1 + \omega_2^2\nonumber \\
		\dot{\alpha} &= \theta_1 + 2 u %\nonumber \\
	\end{align}
	%
	The scalars $\omega_1$, $\omega_2$, $\theta_1$ and $\theta_2$ are acceleration noise terms such as gear backlash, friction, and modeling errors. If our measurement consists of the $\theta$ and $\omega$ states, it follows that we can write the state space equation as 
	%
	\begin{align}
		\begin{bmatrix}
		 \dot{\theta} \\ \dot{\omega} \\ \dot{\alpha}
		\end{bmatrix}
		& =
		\begin{bmatrix}
		0 & 1 & 1 \\
		1 & 0 & 2.5 \\
		0 & 0 & 0
		\end{bmatrix}
		+
		\begin{bmatrix}
		0 \\ 1 \\ 2
		\end{bmatrix} u
		+
		\begin{bmatrix}
		 3.5 \omega_1 + 6 \theta_2 \\
		 \omega_1 + \omega_2^2 \\
		 \theta_1
		\end{bmatrix} \nonumber \\
		%
		y &= \begin{bmatrix}
		1 & 1 & 0
		\end{bmatrix} +
		\begin{bmatrix}
		\theta \\ \omega \\ \alpha
		\end{bmatrix} + \begin{bmatrix}
		{v_x} \\ {v_y} \\ {v_z}
		\end{bmatrix}
	\end{align}
	where $v = [v_x, v_y, v_z]^T$ is the linear velocity vector for  the robot.
\end{example}

\begin{example}
	Suppose that 
	\begin{align}
		A = \begin{bmatrix}
		0 & 1 \\ 0 & 0
		\end{bmatrix}
	\end{align}
	%
	It follows that
	%
	\begin{align}
		e^{At} &= \sum_{j=0}^{\infty} \dfrac{(At)^j}{j!} \nonumber \\
		       &= (At)^0 + (At)^1 + \frac{(At)^2}{2!} +  \frac{(At)^3}{3!} + \ldots \nonumber \\
		       &= I + At
	\end{align}	
	where the last term follows from the fact that $A^k = 0$ for $k>1$ so that 
	%
	\begin{align}
		e^{At} = \begin{bmatrix}
		1 & 0 \\ 0 & 1
		\end{bmatrix}
		+ 
		\begin{bmatrix}
		0 & t \\ 0 & 0
		\end{bmatrix}
		= 
		\begin{bmatrix}
		1 & t \\ 0 & 1
		\end{bmatrix}
	\end{align}
	%
	Using the expression for the inverse Laplace transform earlier, we have 
	%
	\begin{align}
		e^{At} &= \mathcal{L}^{-1}\left[\left(sI-A\right)^{-1}\right] \nonumber \\
		&= \mathcal{L}^{-1}\left(
		\begin{bmatrix}
		s & -1 \\ 0 & s
		\end{bmatrix}^{-1}\right) \nonumber \\
		&= \mathcal{L}^{-1} 
		\begin{bmatrix}
		1/s & 1/s^2 \\ 0 & 1/s
		\end{bmatrix} \nonumber \\
		&= \begin{bmatrix}
		1 & t \\ 0 & 1
		\end{bmatrix}
		\label{eq:example_matrix_eq}
	\end{align}
\end{example}

\begin{homework}
	Find the eigendata of the matrix A in \eqref{eq:example_matrix_eq}. Then determine the following terms using the eigenvector and eigenvalue that you may find:
	$\hat{A}, Q$ and $e^{At}$.
\end{homework}

\begin{homework}
	Produce a one-page report on a control system transfer function.
\end{homework}
%
\section{State Space Standard Forms}
For a linear system, there are many possible state space models that can result in the same \textit{transfer function dynamics}. Therefore, standardizing the state space model structures is 
relevant for solving problems in a conformal way. For consider the following input-output system linear difference equation
%
\begin{align}
	y_n + a_1 y_{n-1}  + \ldots + a_{n-1} y_1 + a_n y = b_0 u_n + b_1 u_{n-1} + \ldots + b_{n-1} u_1 + b_n u
\end{align}
%
with $u$ and $y$ serving respectively as the input and output, and $y_n$ serving as the $n$th derivative of $y$ with respect to time. If we take the Laplace transform of both sides, we have
%
\begin{align}
	Y(s) \left(s^n + a_1s^{n-1}+\ldots + a_{n-1}s + a_n\right) = U(s)\left(b_0 s^n + b_1 s^{n-1} + \ldots + b_{n-1} s + b_n\right)
\end{align}
%
so that the transfer function from the input $u$ to the output $y$ can be written as 
%
\begin{align}
	\dfrac{Y(s)}{U(s)} = \dfrac{b_0 s^n + b_1 s^{n-1} + \ldots + b_{n-1} s + b_n}{s^n + a_1s^{n-1}+\ldots + a_{n-1}s + a_n}
	\label{eq:transfer_fcn}
\end{align}

\subsection{Companion form}

In \textit{companion form} representation, the coefficients of the transfer function in \eqref{eq:transfer_fcn} are arranged along its far rows or columns. An example would be 
%
\begin{align}
	\begin{bmatrix} 0 & 0 & 0 & \cdots & 0 & -a_0 \\
	1 & 0 & 0 & \cdots & 0 & -a_1 \\
	0 & 1 & 0 & \cdots & 0 & -a_2 \\
	0 & 0 & 1 & \cdots & 0 & -a_3 \\
	\vdots & \vdots & \vdots &\ddots & \vdots & \vdots \\
	0 & 0 & 0 & \cdots & 1 & -a_{n-1} 
	\end{bmatrix}
\end{align}
%
or
%
\begin{align}
	\begin{bmatrix} -a_{n-1} & -a_{n-2} & -a_{n-3} & \cdots & -a_1 & -a_0 \\
	1 & 0 & 0 & \cdots & 0 & 0 \\
	0 & 1 & 0 & \cdots & 0 & 0 \\
	0 & 0 & 1 & \cdots & 0 & 0 \\
	\vdots & \vdots & \vdots &\ddots & \vdots & \vdots \\
	0 & 0 & 0 & \cdots & 1 & 0 
	\end{bmatrix}
\end{align}

In general, we use the convenient \textit{observable} and \textit{controllable} canonical forms in control theory. They are exactly the transpose of one another and using either for control design simplifies the system structure so that it can be readily manipulated for a desired control.

\subsection{Modal Form}

The modal form is the dual to the companion form. In the modal form, the state matrix is a diagonal matrix with non-repeating eigenvalues such that the control has a unitary influence on each eigenspace, and the output is a linear combination of the contributions from the eigenspaces. That is,
%
\begin{subequations}
	\begin{align}
	A &= \begin{bmatrix} -p_1 & 0 & 0 & \cdots & 0 & 0 \\
	0 & -p_2 & 0 & \cdots & 0 & 0 \\
	0 & 0 & -p_3 & \cdots & 0 & 0 \\
	\vdots & \vdots & \vdots &\ddots & \vdots & \vdots \\
	0 & 0 & 0 & \cdots & 0 & -p_n
	\end{bmatrix} \\
	%
	B &= \begin{bmatrix} 1 \\ 1 \\ \vdots \\ 1 \end{bmatrix} \quad
	%
	C = \begin{bmatrix} c_1 & c_2  & \cdots & c_n \end{bmatrix}
	\end{align}
\end{subequations}
%
\begin{homework}
	Write out the solution to \autoref{eq:companion_ex} in modal form.
\end{homework}

\subsection{Controllable Canonical Form}

When we want to design a controller that leverages the full state of the system (assuming this is known), often the \textit{controllable canonical form} will come in handy. It is expressed as follows:
%
\begin{subequations}
	\begin{align}
	A &= \begin{bmatrix} -a_1 & -a_2 & -a_3 & \cdots & -a_{n-1} & -a_n \\
	1 & 0 & 0 & \cdots & 0 & 0 \\
	0 & 1 & 0 & \cdots & 0 & 0 \\
	0 & 0 & 1 & \cdots & 0 & 0 \\
	\vdots & \vdots & \vdots &\ddots & \vdots & \vdots \\
	0 & 0 & 0 & \cdots & 1 & 0 
	\end{bmatrix} 
	\\
		B &= \begin{bmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{bmatrix}
	\quad
	C = \begin{bmatrix} b_1 & b_2 & b_3 & \cdots & b_n \end{bmatrix}
	\quad 
	D = \begin{bmatrix} b_0 \end{bmatrix}
	\end{align}
\end{subequations}

\begin{example}
	For the system 
	\begin{align}
		\dfrac{Y(s)}{U(s)} = \dfrac{5s^2-s+8}{s^2+4s-2}
	\end{align}
	%
	we can realize the state space representation in canonical form as follows:
	\begin{enumerate}
%		\item First we rewrite the transfer function as 
%		%
%		\begin{align}
%		\dfrac{Y(s)}{U(s)} = \dfrac{s^3 + 5/2s^2-1/2s+4}{s^2+4s-2}
%		\end{align}
		%
		\item Observe that $n$ from \eqref{eq:transfer_fcn} is $3$, \ie the highest $s$ exponent in the given transfer function. 
		%
		\item It follows that we have $a_0= -2$ and $a_1 = 4$; and $b_0 = 1, \, b_1=-21$, \, $b_2 = 102$, so that we can write the state space model as
		%
		\begin{align}
			  \begin{bmatrix}
			  \dot{x}_1 
			  \\
			  \dot{x}_2
			  \end{bmatrix} 
			  &=
			  \begin{bmatrix}
			  0 & 2  \\
			  1 & -4 
			  \end{bmatrix}
			  %			  
			  \begin{bmatrix}
			  {x}_1 
			  \\
			  {x}_2
			  \end{bmatrix} 
			  +
			  %			  
			  \begin{bmatrix}
			  1
			  \\
			  0
			  \end{bmatrix} 			  
			  %			  
			  \begin{bmatrix}
			  {u}_1 
			  &
			  {u}_2
			  \end{bmatrix} \nonumber \\
			  %
			  y &= \begin{bmatrix}
			  -21 & 102
			  \end{bmatrix}
			  %			  
			  \begin{bmatrix}
			  {x}_1 
			  \\
			  {x}_2
			  \end{bmatrix} 
			  + 
			  \bm{u}
		\end{align}
	\end{enumerate}
\end{example}
%
\begin{homework}
	Derive the companion form for the system:
	\begin{align}
	\dfrac{Y(s)}{U(s)} = \dfrac{3s^2-2s+1}{s^2-8s+5}
	\end{align}
	\label{eq:companion_ex}
\end{homework}

The controllable canonical form is helpful in when using the pole placement method for controller design. However, the system's transformation to companion form is based on the controllability matrix which is almost always numerically singular for mid-range orders. It should be avoided for computation when possible.

\subsection{Observable Canonical Form}

In observable canonical form, the transfer function coefficients of \eqref{eq:transfer_fcn} are written in the rightmost column of the $A$ matrix similar to the companion canonical form but the $B$ matrix takes a different form. It is given as follows:
%
\begin{align}
A &= \begin{bmatrix} 0 & 0 & 0 & \cdots & 0 & -a_0 \\
1 & 0 & 0 & \cdots & 0 & -a_1 \\
0 & 1 & 0 & \cdots & 0 & -a_2 \\
0 & 0 & 1 & \cdots & 0 & -a_3 \\
\vdots & \vdots & \vdots &\ddots & \vdots & \vdots \\
0 & 0 & 0 & \cdots & 1 & -a_{n-1} 
\end{bmatrix} \\
%
B &= \begin{bmatrix}
	b_n - a_n b_0 \\
	%	
	b_{n-1} - a_{n-1} b_0 \\
	%	
	b_{n-2} - a_{n-2} b_0 \\
	%	
	\vdots \\
	%
	b_{1} - a_{1} b_0 \\
\end{bmatrix}
%
\quad 
C = \begin{bmatrix}
 0  & 0 & \ldots & 1
\end{bmatrix}, \quad D = b_0
 \end{align}
%
This observable canonical form is ill-conditioned for most state-space computation. It should be avoided for computation when possible as its controllability matrix is almost always numerically singular for mid-range orders.

The observable and controllable canonical forms' matrices are respectively transposes of one another.

%
\begin{homework}
Transform the exercise of \ref{eq:companion_ex} to observable canonical form.
\end{homework}

\section{Nonlinear Systems}

\textit{All the world is a nonlinear system. He linearized to the right. He linearized to the left. Till nothing was right. And nothing was left. -- Stephen Billings.}

Our treatment of dynamical so far has involved linear systems. These are optimistic models of the real world as in the reality, nothing is really linear. In general, a nonlinear system is a system which is not linear \ie, does not satisfy the \textit{principle of superposition}. Even a simple resistor exhibits nonlinearity. However, we utilize Ohm's law in approximating the dynamics of a resistor. This is because the equation is valid over a wide enough operating range. In this light, while we may say linear systems do not exist in real life, linear systems is a useful tool for describing nonlinear systems. We will write a general nonlinear system with the equation
%
\begin{align}
	\dot{x} &= f(x, u, w) \nonumber \\
	y &= h(x, v)
\end{align}
%
where $f(\cdot)$ and $h(\cdot)$ are arbitrary vector valued functions, $w$ denotes the process noise, and $v$ denotes the measurement noise. We have a time-varying system if $f(\cdot)$ and $h(\cdot)$ are explicit functions of $t$, otherwise, the system is termed time-invariant. Suppose that $f(x, u, w) = Ax + Bu + w$ and $h(x,v) = Hx + v$, then the system is linear. Otherwise, the system is nonlinear.

Often, we will need to linearize a nonlinear system in order to properly analyze its stability properties or synthesize its parameters for a particular control application. Suppose we have a nonlinear vector function $f(\cdot)$ of a scalar $x$, we can expand $f(x)$ in a Taylor series around some nominal operating point, $x = \bar{x}$ so that 
%
\begin{align}
	f(x) = f(\bar{x}) + \dfrac{\partial f}{\partial x} \bigg\rvert_{\tilde{x}} \tilde{x}+ \dfrac{1}{2!} \dfrac{\partial^2f}{\partial x^2} \bigg\rvert_{\tilde{x}} \tilde{x}^2 + \dfrac{1}{3!} \dfrac{\partial^3f}{\partial x^3} \bigg\rvert_{\tilde{x}} \tilde{x}^3 +  \ldots
\end{align}
%
where $\tilde{x} = x - \bar{x}$. For a $2 \times 1$ vector $x$, we can write $f(x)$ as follows:
%
\begin{align}
	f(x) &= f(\bar{x}) + \dfrac{\partial f}{\partial x_1} \bigg\rvert_{\tilde{x}} \tilde{x}_1 + \dfrac{\partial f}{\partial x_2} \bigg\rvert_{\tilde{x}} \tilde{x}_2 + \dfrac{1}{2!} \left(\dfrac{\partial^2f}{\partial x_1^2} \bigg\rvert_{\tilde{x}} \tilde{x}_1^2 + \dfrac{\partial^2f}{\partial x_2^2} \bigg\rvert_{\tilde{x}} \tilde{x}_2^2 + 2 \dfrac{\partial ^2 f}{\partial x_1 x_2}\bigg \rvert_{\tilde{x}} \tilde{x}_1 \tilde{x}_2 \right) + \nonumber \\
	%
	& 
	%
	\dfrac{1}{3!} \left(\dfrac{\partial^3f}{\partial x_1^3} \bigg\rvert_{\tilde{x}} \tilde{x}_1^3 + \dfrac{\partial^3f}{\partial x_2^3} \bigg\rvert_{\tilde{x}} \tilde{x}_2^3 + 3 \dfrac{\partial ^3 f}{\partial x_1^2 x_2}\bigg \rvert_{\tilde{x}} \tilde{x}_1^2  \tilde{x}_2 + 3 \dfrac{\partial ^3 f}{\partial x_1 x_2^2}\bigg \rvert_{\tilde{x}} \tilde{x}_1  \tilde{x}_2^2  \right) + \ldots
\end{align}
 %
 which can be compactly written as 
 %
 \begin{align}
 	f(x) & = f(\tilde{x}) + \left(\tilde{x}_1 \dfrac{\partial}{\partial x_1} + \tilde{x}_2 \dfrac{\partial}{\partial x_2}\right)f\bigg\rvert_{\tilde{x}} +
 	%
 	\dfrac{1}{2!} \left(\tilde{x}_1 \dfrac{\partial}{\partial x_1} + \tilde{x}_2 \dfrac{\partial}{\partial x_2}\right)^2f\bigg\rvert_{\tilde{x}} + \nonumber \\
 	%
 	& 
 	%
 	\qquad \dfrac{1}{3!}\left(\tilde{x}_1 \dfrac{\partial}{\partial x_1} + \tilde{x}_2 \dfrac{\partial}{\partial x_2}\right)^3f\bigg\rvert_{\tilde{x}} + \ldots
 \end{align}
%
And when $n$ is an $n\times 1$ vector, the vector $f(x)$, expanded in a Taylor series becomes
%
\begin{align}
	f(x) &=  f(\tilde{x}) + \left(\tilde{x}_1 \dfrac{\partial}{\partial x_1} + \ldots + \tilde{x}_n \dfrac{\partial}{\partial x_n}\right)f\bigg\rvert_{\tilde{x}} +
	%
	\dfrac{1}{2!} \left(\tilde{x}_1 \dfrac{\partial}{\partial x_1} + \ldots + \tilde{x}_n \dfrac{\partial}{\partial x_n}\right)^2f\bigg\rvert_{\tilde{x}} + \nonumber \\
	%
	& 
	%
	\qquad \dfrac{1}{3!}\left(\tilde{x}_1 \dfrac{\partial}{\partial x_1} + \ldots + \tilde{x}_n \dfrac{\partial}{\partial x_n}\right)^3f\bigg\rvert_{\tilde{x}} + \ldots
\end{align}
%
Suppose we define the operation $D^k_{\tilde{x}}f$ as 
%
\begin{align}
	D^k_{\tilde{x}} = \left(\sum_{i=1}^{n} \tilde{x}_i \dfrac{\partial}{\partial x_i}\right)^k f(x) \bigg \rvert_{\tilde{x}}
\end{align}
%
so that we can define $f(x)$ in Taylor series form as 
%
\begin{align}
	f(x) = f(\tilde{x}) + D_{\tilde{x}} f + \dfrac{1}{2!} D^2_{\tilde{x}} f + \dfrac{1}{3!} D^3_{\tilde{x}} f + \ldots
\end{align}