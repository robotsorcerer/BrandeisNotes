\chapter{Motion Planning} 
\label{chap:moplan}

Planning is an important part of robotics. Consider a child (one-year-old) trying to execute a certain simple task such as drinking from a cup of milk. For such a child, this is a very difficult task as they are yet to develop the motor control section of their brain that helps with the hand-eye coordination necessary for the execution of this simple motor task. As such a child evolves, different parts of their brain develops such as the pre-frontal lobes and visual cortex. These, together with innate skills and learning from their environment helps them in eventually mastering the most mundane tasks that aids them throughout life. The way the human brain develops is still a mystery to scientists and if we can understand how the brain works, it would be easy for us to replicate most of these simple automation tasks in real-life. However, given the complexity required for such mastery, researchers have been chipping away at more simpler  ways to plan automation behaviors for a robot. The rest of this course is divided into two phases. In  the first phase, we will deal with works that emerged in the '90's and early 2000's on planning and execution for robots in the world. These tended to leverage subjects that ran the gamut of control theory, information theory and uncertainty quantification. A second parallel in planning and automation that is an evolving field of research has been reinforcement learning and deep reinforcement learning. This area of research involved largely using very deep neural networks (in most cases) as function approximators in encoding future behaviors of a robot by extensively training such a function approximator in a simulator or in a controlled environment.

As the field of studies in these areas are relatively new, there is no certain textbook or mantra for learning what the state-of-the-art is. However, there is a vast array of literature out there in the world on these subjects. Authors of particular interest whose work are very influential are (listed in no particular order of importance) Lydia Kavraki, Steven Lavalle, James Kuffner, Marc Deisenroth, Pieter Abbeel, Ken Goldberg, Sergey Levine and CHelsea Finn among others. In particular, I would refer you to the following text and survey paper as a useful reference throughout the rest of what follows in these notes.
%
\begin{itemize}
	\item LaValle, Steven M. Planning algorithms. Cambridge university press, 2006. \textit{Available at: \href{http://planning.cs.uiuc.edu/}{http://planning.cs.uiuc.edu/}}
	%
	\item Deisenroth, M. P. (2011). A Survey on Policy Search for Robotics. Foundations and Trends in Robotics, 2(1), 1â€“142. \textit{Available at: \href{https://www.nowpublishers.com/article/Details/ROB-021}{https://www.nowpublishers.com/article/Details/ROB-021}}.
\end{itemize}
%
If you are having trouble downloading any of these materials, please email the instructor for an electronic copy.

\section{Planning: Motion/Trajectory Planning}

In robotics, by planning, we mean the task of automating mechanical or pneumatic systems with the capability for sensing, actuation, and computation abilities. In general, we want to have some sort of algorithm that converts a high-level description of a task to a lower-level one such that we can realize what we want in the real world. \textit{In control systems}, we often design local feedback laws that can act on the dynamics (an encoding of the behavior of the world) of the system so as to realize that which we desire to control. In executing these feedback control laws, we often need a sense of measure of the position and motion of objects in the environment. Typically, this is the sensing problem and it is typically achieved with a vision or tactile or tactile-vision sensor.  Together with the sensed position of the world, we are able to accurately execute an automation task as desired. In \textit{artificial intelligence}, the planning problem is a little loose. Here, the task might involve using discretizing a continuous state space, approximating a complex world with a microcosm of its model.   

Our focus in this chapter is on the algorithmic and the computational issues that arise in planning within several disciplines. In this sentiment, we introduce the notions that enable us to accurately represent a planning algorithm as completely as possible. These are the \textit{states}, \textit{time}, \textit{actions},  \textit{cost} and the \textit{plan}.
%
\begin{definition}[State]
	The state is defined broadly enough to capture all subjective unknowns that might influence future behaviors by a system. For a robot navigating within a grid, for example, the state could be the location of the grid blocks, obstacles and edges within the grid. States can be discrete or continuous. 
\end{definition}
%
\begin{definition}[Time]
The planning problem occurs over a certain (time) horizon. This horizon is often explicitly modeled or implicitly. The important consideration is that a proper sequence must be maintained. Just as a state, time can be dicretized or made continuous.
\end{definition}
%
\begin{definition}[Actions]
	This is a taxonomy that is often used in the AI/computer science robotics world. It is an input that is given to a system that causes it to transition from one state to another state. In control theory literature, you might come across the same term as control/control law.
\end{definition}
%
\begin{definition}[Criterion]
	The criterion is the embodiment of the task's goals. It defines the problem to be solved and provides a measure of how well we are performing towards realizing our objective during the task's execution. There are two functions that we generally concern ourselves about in this regard: 
	\begin{itemize}
	\item \textit{Feasibility}, which is to determine a plan that enables us to reach a goal state, without regard to efficiency
	%
	\item \textit{Optimality}, which is to determine a plan that fulfills certain index or indices of performance such that the end result is arrived at through the most optimal means.
	\end{itemize}
\end{definition}
%
\begin{definition}[Plan]
	A plan imposes a definite strategy or behavior on the decision-making agent. It could be the sequence of actions taken or actions as a function of the state. The plan enables \textit{feedback or reactive plans.}
\end{definition}
%

\section{Planning in Discrete Spaces}
Discrete planning shall involve planning in state spaces where the dimension of the state is finite ot at least infinitely countable \ie, there exists a unique integer that can be assigned to every state. As such, the concepts of representing the state space with a geometric model or complicated differential equations shall not be dealt with herein. We will generally relegate the concepts of uncertainty and avoid methods of representing uncertainty with probability theory.